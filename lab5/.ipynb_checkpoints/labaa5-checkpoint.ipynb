{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Лабораторна робота №5.*\n",
    "# *По темі : Пакет Tensorflow*\n",
    "***\n",
    "\n",
    "\n",
    "## **Виконав:** \n",
    "* ## Студент 4 курсу\n",
    "* ## Группи АнД-41\n",
    "* ## Сірий Артем Олександрович\n",
    "* ## Варінат №11\n",
    "\n",
    "***\n",
    "\n",
    "## *Завдання :*\n",
    "## 1. Виконати вирішення задачs класифікації для 3 класів з набору даних food101 з використанням різних моделей нейронних мереж:\n",
    "* ## CNN модель з лабораторної роботи 4\n",
    "* ## Resnet модель\n",
    "* ## Efficientnet модель (моделі 1.1-1.3 з використанням оптимізатора Adam)\n",
    "* ## Моделі 1.2,1.3 з використанням оптимізатора SGD.\n",
    "* ## Моделі 1.2,1.3 отримані за допомогою tf.keras.applications та треновані з використанням fine-tuning (останні 10 шарів)\n",
    "## 2. Індекси класів визначити індивідуально за залежностями: i1=n-1,i2=n+29,i3=n+59 (де і1,і2,і3 - індекс класу (починаючи з 0) у відсортованому за алфавітом наборі даних, n - номер за списком групи. \n",
    "## Класи : i1=11-1=10 , i2=11+29=40 , i3=11+59=70\n",
    "## 3. Порівняти результати моделювання із використанням TensorBoard\n",
    "## 4. Графік(и) порівняння результатів завантажити у форматі .svg та вставити у підсумковий файл поряд із та відповідними висновками\n",
    "## 5. Результати оформити у вигляді файлу з кодом для моделювання та візуалізації у форматі .ipynb\n",
    "## 6. Результати викласти у репозиторії GitHub (папка Lab5).\n",
    "## 7. Підготуватися до захисту лабораторрної роботи (пояснення коду, відповіді на запитання за темою)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pathlib\n",
    "import random\n",
    "import matplotlib.cbook as cbook\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
    "from tensorflow.keras.losses import mae, mse\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Імпортуємо класи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "data_folder_bruschetta = pathlib.Path(\"../Lab4/train/\")\n",
    "class_names = np.array(sorted([item.name for item in data_folder_bruschetta.glob('*')]))\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_random_image(target_dir, target_class):\n",
    "  # Setup target directory (we'll view images from here)\n",
    "  target_folder = target_dir+target_class\n",
    "\n",
    "  # Get a random image path\n",
    "  random_image = random.sample(os.listdir(target_folder), 1)\n",
    "\n",
    "  # Read in the image and plot it using matplotlib\n",
    "  img = mpimg.imread(target_folder + \"/\" + random_image[0])\n",
    "  plt.imshow(img)\n",
    "  plt.title(target_class,color='white')\n",
    "  plt.axis(\"off\")\n",
    "\n",
    "  print(f\"Image shape: {img.shape}\") # show the shape of the image\n",
    "\n",
    "  return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Виведемо 10 рандомних фото"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Системе не удается найти указанный путь: '../Lab4/train/pad_thai'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3776/496445979.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'off'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mview_random_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"../Lab4/train/\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_class\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfoo_choice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3776/2519629753.py\u001b[0m in \u001b[0;36mview_random_image\u001b[1;34m(target_dir, target_class)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m   \u001b[1;31m# Get a random image path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m   \u001b[0mrandom_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_folder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m   \u001b[1;31m# Read in the image and plot it using matplotlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] Системе не удается найти указанный путь: '../Lab4/train/pad_thai'"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg0AAADNCAYAAAA7b0MJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAADs0lEQVR4nO3ZwU0DUQxAwf2IEpIz238tSRE5Qw+mgSDeSkQBMXO1Dz4+yWtmNgCA77w8+wAA4G8QDQBAIhoAgEQ0AACJaAAAEtEAACSvR5ZPp9Ps+/6gUwCAZ7terx8zc743OxQN+75vl8vlZ64CAH6dtdbtq5n3BACQiAYAIBENAEAiGgCARDQAAIloAAAS0QAAJKIBAEhEAwCQiAYAIBENAEAiGgCARDQAAIloAAAS0QAAJKIBAEhEAwCQiAYAIBENAEAiGgCARDQAAIloAAAS0QAAJKIBAEhEAwCQiAYAIBENAEAiGgCARDQAAIloAAAS0QAAJKIBAEhEAwCQiAYAIBENAEAiGgCARDQAAIloAAAS0QAAJKIBAEhEAwCQiAYAIBENAEAiGgCARDQAAIloAAAS0QAAJKIBAEhEAwCQiAYAIBENAEAiGgCARDQAAIloAAAS0QAAJKIBAEhEAwCQiAYAIBENAEAiGgCARDQAAIloAAAS0QAAJKIBAEhEAwCQiAYAIBENAEAiGgCARDQAAIloAAAS0QAAJKIBAEhEAwCQiAYAIBENAEAiGgCARDQAAIloAAAS0QAAJKIBAEhEAwCQiAYAIBENAEAiGgCARDQAAIloAAAS0QAAJKIBAEhEAwCQiAYAIBENAEAiGgCARDQAAIloAAAS0QAAJKIBAEhEAwCQiAYAIBENAEAiGgCARDQAAIloAAAS0QAAJKIBAEhEAwCQiAYAIBENAEAiGgCARDQAAIloAAAS0QAAJKIBAEhEAwCQiAYAIBENAEAiGgCARDQAAIloAAAS0QAAJKIBAEhEAwCQiAYAIBENAEAiGgCARDQAAIloAAAS0QAAJKIBAEhEAwCQiAYAIBENAEAiGgCARDQAAIloAAAS0QAAJKIBAEhEAwCQiAYAIBENAEAiGgCARDQAAIloAAAS0QAAJKIBAEhEAwCQiAYAIBENAEAiGgCARDQAAIloAAAS0QAAJKIBAEhEAwCQiAYAIBENAEAiGgCARDQAAIloAAAS0QAAJKIBAEhEAwCQiAYAIBENAEAiGgCARDQAAIloAAAS0QAAJKIBAEhEAwCQiAYAIBENAEAiGgCARDQAAIloAAAS0QAAJKIBAEhEAwCQiAYAIBENAEAiGgCARDQAAIloAAAS0QAAJKIBAEhEAwCQrJnpy2u9b9t2e9w5AMCTvc3M+d7gUDQAAP+X9wQAkIgGACARDQBAIhoAgEQ0AACJaAAAEtEAACSiAQBIRAMAkHwCkYYbO1ybnBEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1440x1440 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "foo = [\"bruschetta\", \"grilled_salmon\", \"pad_thai\"] \n",
    "secure_random = random.SystemRandom()\n",
    "plt.figure(figsize=(20,20))\n",
    "for p in range(10):\n",
    "    foo_choice = secure_random.choice(foo)\n",
    "    plt.subplot(5,2,p+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid('off')\n",
    "    plt.imshow(view_random_image(target_dir=\"../Lab4/train/\", target_class=foo_choice))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(11)\n",
    "\n",
    "# Зведення до бінарного виду (чорно-білого)\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_dir = \"../Lab4/train/\"\n",
    "test_dir = \"../Lab4/test/\"\n",
    "\n",
    "train_data = train_datagen.flow_from_directory(test_dir,\n",
    "                                               batch_size=32, # number of images to process at a time \n",
    "                                               target_size=(224, 224), # convert all images to be 224 x 224\n",
    "                                               class_mode='categorical',\n",
    "                                               seed=11)\n",
    "\n",
    "valid_data = valid_datagen.flow_from_directory(train_dir,\n",
    "                                               batch_size=32,\n",
    "                                               target_size=(224, 224),\n",
    "                                               class_mode='categorical',\n",
    "                                               seed=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow_hub as hub\n",
    "IMAGE_SHAPE=(224,224)\n",
    "\n",
    "def create_tensorboard_callback(dir_name, experiment_name):\n",
    "  log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "  tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "      log_dir=log_dir\n",
    "  )\n",
    "  print(f\"Saving TensorBoard log files to: {log_dir}\")\n",
    "  return tensorboard_callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = Sequential([\n",
    "  Conv2D(10, 3, activation='relu', input_shape=(224, 224, 3)),\n",
    "  Conv2D(10, 3, activation='relu'),\n",
    "  MaxPool2D(),\n",
    "  Conv2D(10, 3, activation='relu'),\n",
    "  Conv2D(10, 3, activation='relu'),\n",
    "  MaxPool2D(),\n",
    "  Flatten(),\n",
    "  Dense(3, activation='softmax') \n",
    "])\n",
    "\n",
    "model_1.compile(loss=\"categorical_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "import datetime\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "history_1 = model_1.fit(train_data,\n",
    "                        epochs=7,\n",
    "                        steps_per_epoch=len(train_data),\n",
    "                        validation_data=valid_data,\n",
    "                        validation_steps=len(valid_data),\n",
    "                        callbacks=[create_tensorboard_callback(dir_name=\"Lab5\", experiment_name=\"CNN\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history_1.history).plot(figsize=(10, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir='./Lab5/CNN/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with cbook.get_sample_data(r'D:\\Program\\Microsoft VS Code Prog\\Neural Networks\\Lab5\\TfBoard\\CNN.jpg') as image_file:\n",
    "    image = plt.imread(image_file)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.imshow(image)\n",
    "ax.set_title(type(image))\n",
    "\n",
    "fig.set_figwidth(25)\n",
    "fig.set_figheight(25)  \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_results = pd.DataFrame(history_1.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_url=\"https://tfhub.dev/google/imagenet/resnet_v1_101/feature_vector/5\"\n",
    "efficientnet_url=\"https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1\"\n",
    "\n",
    "def create_BC_model(model_url):\n",
    "  # Download the pretrained model and save it as a Keras layer\n",
    "  feature_extractor_layer = hub.KerasLayer(model_url,\n",
    "                                           trainable=False, # freeze the underlying patterns\n",
    "                                           name='feature_extraction_layer',\n",
    "                                           input_shape=IMAGE_SHAPE+(3,)) # define the input image shape\n",
    "  \n",
    "  # Create our own model\n",
    "  model = tf.keras.Sequential([\n",
    "    feature_extractor_layer, # use the feature extraction layer as the base\n",
    "    Dense(3, activation='sigmoid', name='output_layer') # create our own output layer      \n",
    "  ])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model= create_BC_model(resnet_url)\n",
    "resnet_model.compile(\n",
    "    loss=\"categorical_crossentropy\", \n",
    "    optimizer=tf.keras.optimizers.Adam(), \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "history_2 = resnet_model.fit(train_data, \n",
    "                epochs=7, \n",
    "                validation_data=valid_data, \n",
    "                callbacks=[create_tensorboard_callback(dir_name=\"Lab5\", experiment_name=\"resnet\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history_2.history).plot(figsize=(10, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir='./Lab5/resnet/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with cbook.get_sample_data(r'D:\\Program\\Microsoft VS Code Prog\\Neural Networks\\Lab5\\TfBoard\\Resnet.jpg') as image_file:\n",
    "    image = plt.imread(image_file)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.imshow(image)\n",
    "ax.set_title(type(image))\n",
    "\n",
    "fig.set_figwidth(25)\n",
    "fig.set_figheight(25)  \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_results = pd.DataFrame(history_2.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efficientnet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientnet_model= create_BC_model(efficientnet_url)\n",
    "efficientnet_model.compile(\n",
    "    loss=\"categorical_crossentropy\", \n",
    "    optimizer=tf.keras.optimizers.Adam(), \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "history_3 = efficientnet_model.fit(train_data, \n",
    "                epochs=7, \n",
    "                validation_data=valid_data, \n",
    "                callbacks=[create_tensorboard_callback(dir_name=\"Lab5\", experiment_name=\"efficientnet\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientnet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history_3.history).plot(figsize=(10, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir='./Lab5/efficientnet/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with cbook.get_sample_data(r'D:\\Program\\Microsoft VS Code Prog\\Neural Networks\\Lab5\\TfBoard\\Efficientnet.jpg') as image_file:\n",
    "    image = plt.imread(image_file)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.imshow(image)\n",
    "ax.set_title(type(image))\n",
    "\n",
    "fig.set_figwidth(25)\n",
    "fig.set_figheight(25)  \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientnet_results = pd.DataFrame(history_3.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet + sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model2= create_BC_model(resnet_url)\n",
    "resnet_model2.compile(\n",
    "    loss=\"categorical_crossentropy\", \n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.01), \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "history_4 = resnet_model2.fit(train_data, \n",
    "                epochs=7, \n",
    "                validation_data=valid_data, \n",
    "                callbacks=[create_tensorboard_callback(dir_name=\"Lab5\", experiment_name=\"resnet_sgd\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir='./Lab5/resnet_sgd/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with cbook.get_sample_data(r'D:\\Program\\Microsoft VS Code Prog\\Neural Networks\\Lab5\\TfBoard\\Resnet_SGD.jpg') as image_file:\n",
    "    image = plt.imread(image_file)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.imshow(image)\n",
    "ax.set_title(type(image))\n",
    "\n",
    "fig.set_figwidth(25)\n",
    "fig.set_figheight(25)  \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_sgd_results = pd.DataFrame(history_4.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efficientnet + sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientnet_model2= create_BC_model(efficientnet_url)\n",
    "efficientnet_model2.compile(\n",
    "    loss=\"categorical_crossentropy\", \n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.01), \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "history_5 = efficientnet_model2.fit(train_data, \n",
    "                epochs=7, \n",
    "                validation_data=valid_data, \n",
    "                callbacks=[create_tensorboard_callback(dir_name=\"Lab5\", experiment_name=\"efficientnet_sgd\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir='./Lab5/efficientnet_sgd/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with cbook.get_sample_data(r'D:\\Program\\Microsoft VS Code Prog\\Neural Networks\\Lab5\\TfBoard\\Efficientnet_SGD.jpg') as image_file:\n",
    "    image = plt.imread(image_file)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.imshow(image)\n",
    "ax.set_title(type(image))\n",
    "\n",
    "fig.set_figwidth(25)\n",
    "fig.set_figheight(25)  \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientnet_sgd_results = pd.DataFrame(history_5.history)\n",
    "all_models_results = pd.concat([model_1_results, resnet_results,efficientnet_results,resnet_sgd_results,efficientnet_sgd_results])\n",
    "all_models_results.plot(kind=\"bar\", figsize=(10, 7)).legend(bbox_to_anchor=(1.0, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model=tf.keras.applications.ResNet101(include_top=False)\n",
    "base_model.trainable=False\n",
    "inputs = tf.keras.layers.Input(shape=(224,224,3),name=\"input_layer\")\n",
    "\n",
    "for layer in base_model.layers[-10:]:\n",
    "    layer.trainable=True\n",
    "\n",
    "x=base_model(inputs)\n",
    "x=tf.keras.layers.GlobalAveragePooling2D(name=\"gap_layer\")(x)\n",
    "outputs= tf.keras.layers.Dense(3,activation=\"sigmoid\",name=\"output_layer\")(x)\n",
    "\n",
    "model_resnet_ft=tf.keras.Model(inputs,outputs)\n",
    "model_resnet_ft.compile(\n",
    "    loss='categorical_crossentropy', \n",
    "    optimizer=tf.keras.optimizers.Adam(), \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "history_resnet_ft =  model_resnet_ft.fit(train_data, \n",
    "                        epochs=7, \n",
    "                        steps_per_epoch=int(0.1*len(train_data)), \n",
    "                        validation_data=valid_data, \n",
    "                        validation_steps=int(0.1*len(valid_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet_ft.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download fine-tuned model from Google Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://storage.googleapis.com/ztm_tf_course/food_vision/07_efficientnetb0_fine_tuned_101_classes_mixed_precision.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!mkdir downloaded_fine_tuned_gs_model # create separate directory for fine-tuned model downloaded from Google Storage\n",
    "#!unzip /content/07_efficientnetb0_fine_tuned_101_classes_mixed_precision -d downloaded_fine_tuned_gs_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loaded_fine_tuned_gs_model = tf.keras.models.load_model(\"/content/downloaded_fine_tuned_gs_model/07_efficientnetb0_fine_tuned_101_classes_mixed_precision\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# *Висновок*\n",
    "***\n",
    "## *В ході виконання лаборатоної роботи було використано бібліотеку з набором фотографій їжі. До варіанту відносились брускети, риба та паста.*\n",
    "## *Загальна кількість вибірки 975 екземплярів. З них 750 на тестову вибірку та 225 на валідаційну. Класи розподілені рівномірно за кількістю.*\n",
    "## *Провевши моделювання 5-ти моделей, було виявлено, що efficientnet з оптимайзером Adam відпрацювала найбільш успішно з поміж усіх. У порівнянні з оптимайзером SGD має кращі значення.*\n",
    "## *Модель resnet показала також високу точність, проте різниця оптимізаційних функцій є досить малою.*\n",
    "## *Щож до моделі CNN, вона є досить поганою у порівнянні з конкурентами.*"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1af1897e727f705b4b45a921e03291b1c553527a2ef9f399fc58ca414bd9107a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
